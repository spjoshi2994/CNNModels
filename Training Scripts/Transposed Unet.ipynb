{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "books/MobileExtraction/Transposed%20Unet.ipynb#books/MobileExtraction/Transposed%20Unet.ipynb## UNET model with transposed convolutions\n",
    "### Changed the no. of filters before last layer to 16 as with 32 filters were learning the road rather than the cracks\n",
    "### Did not learn small cracks well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Dropout, merge, BatchNormalization\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import concatenate,Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Dropout, merge, MaxPool2D\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import concatenate,Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "K.set_image_data_format(data_format='channels_first')\n",
    "'''config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))'''\n",
    "#K.set_image_dim_ordering('tf')\n",
    "\n",
    "'''train = np.load('/home/ubuntu/MobileExtraction/Train256x324-full.npy')\n",
    "labels = np.load('/home/ubuntu/MobileExtraction/Labels256x324-full.npy')\n",
    "print(np.max(train),np.min(train))\n",
    "x = np.argwhere(labels>0)\n",
    "print(x.shape)\n",
    "crf_labels = labels.flatten()\n",
    "for i in range(x.shape[0]):\n",
    "    labels[x[i][0],x[i][1],x[i][2]] = 1\n",
    "train = train.reshape(train.shape[0],256,324)\n",
    "trainNew = np.empty((394,256,324,3),dtype='float32')\n",
    "trainNew[:,:,:,0]=train\n",
    "trainNew[:,:,:,1]=train\n",
    "trainNew[:,:,:,2]=train\n",
    "print(np.unique(labels))\n",
    "import tensorflow as tf\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "print(labels.shape)\n",
    "print(trainNew.shape)\n",
    "labels=labels.astype('uint8')'''\n",
    "smooth = 1.\n",
    "\n",
    "#labels = to_categorical(y=labels,n)\n",
    "#import tensorflow as tf\n",
    "smooth = 1.\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred)-K.log(dice_coef(y_true, y_pred))\n",
    "\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return 1-jacard_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Concatenate\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from skimage import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pad_input(input_img,patch_size=[256,256]):\n",
    "    h = input_img.shape[0]\n",
    "    w = input_img.shape[1]\n",
    "    hMod = h % patch_size[0]\n",
    "    wMod = w % patch_size[1]\n",
    "    hPad=0\n",
    "    wPad=0\n",
    "    if(hMod!=0 or wMod!=0):\n",
    "        hPad = patch_size[0]-hMod\n",
    "        wPad = patch_size[1]-wMod\n",
    "    output = np.pad(input_img, ((0, hPad),(0,wPad),(0,0)), 'constant')\n",
    "    return(output)\n",
    "\n",
    "def prediction_patches(img,patch_size=[256,256]):\n",
    "    img = np.asarray(img).astype('float32')\n",
    "    #print(img.shape)\n",
    "    assert(img.shape[0]%patch_size[0]==0 and img.shape[1]%patch_size[1]==0)\n",
    "    h_patch = int(img.shape[0]/patch_size[0])\n",
    "    w_patch = int(img.shape[1]/patch_size[1])\n",
    "    patches = []\n",
    "    x = 0\n",
    "   \n",
    "    no = 0\n",
    "    for i in range(h_patch):\n",
    "        y = 0 \n",
    "        for j in range(w_patch):\n",
    "            \n",
    "            \n",
    "            patch = img[x:(((i+1)*patch_size[0])),y:(((j+1)*patch_size[1])),:]\n",
    "            #print(y)\n",
    "            #print(patch.shape)\n",
    "            #print(j)\n",
    "            y = ((j+1)*patch_size[1])\n",
    "            #print('yes')\n",
    "            no+=1\n",
    "            patches.append(patch)\n",
    "        x = ((i+1)*patch_size[0])\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def reconstruct_patches(patches= np.ones((16,256,256,3)),img_shape=[1024,1024,3]):\n",
    "    full_img = np.empty(img_shape).astype('float32')\n",
    "    h = img_shape[0]\n",
    "    w = img_shape[1]\n",
    "    c = img_shape[2]\n",
    "    h_patch = int(h / patches.shape[1])\n",
    "    w_patch = int(w / patches.shape[2])\n",
    "    no = 0 \n",
    "    x = 0\n",
    "    \n",
    "    #assert(h_patch*w_patch == patches.shape[0])\n",
    "    for i in range(h_patch):\n",
    "        y = 0\n",
    "        for j in range(w_patch):\n",
    "            full_img[x:(((i+1)*patches.shape[1])),y:((j+1)*patches.shape[2]),:] = patches[no]\n",
    "            #print('yes')\n",
    "            y = ((j+1)*patches.shape[2])\n",
    "            no += 1  \n",
    "        x = ((i+1)*patches.shape[1])\n",
    "    return full_img\n",
    "\n",
    "def LargeDilatedKernels(input_shape):\n",
    "    inputs = Input((input_shape))\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(inputs)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(64,(3,3),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(256,(7,7),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(256,(1,1),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='glorot_uniform',kernel_regularizer=l2(1e-5))(x)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Conv2D(1,(1,1),activation='sigmoid',padding='same',kernel_initializer='glorot_uniform',kernel_regularizer=l2(1e-5))(x)\n",
    "    model = Model(inputs=[inputs],outputs=[x])\n",
    "    return model\n",
    "\n",
    "def dilatedKernels(input_shape):\n",
    "    inputs = Input((input_shape))\n",
    "    conv1 = Conv2D(64,(7,7),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(inputs)\n",
    "    conv2 = Conv2D(64,(7,7),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv1)\n",
    "    conv3 = Conv2D(64,(7,7),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv2)\n",
    "    conv4 = Conv2D(64,(7,7),activation='relu',dilation_rate=(4,4),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv3)\n",
    "    concat1 = concatenate([conv1,conv2,conv3,conv4],axis=1 )\n",
    "    drop1 = Dropout(0.5)(concat1)\n",
    "    conv11 = Conv2D(64,(5,5),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(drop1)\n",
    "    conv12 = Conv2D(64,(5,5),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv11)\n",
    "    conv12 = Dropout(0.5)(conv12)\n",
    "    conv13 = Conv2D(64,(5,5),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv12)\n",
    "    conv14 = Conv2D(64,(5,5),activation='relu',dilation_rate=(4,4),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv13)\n",
    "    concat2 = concatenate([conv11,conv12,conv13,conv14],axis=1 )\n",
    "    drop2 = Dropout(0.5)(concat2)\n",
    "    conv21 = Conv2D(64,(3,3),activation='relu',padding='same',dilation_rate=(1,1),kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(drop2)\n",
    "    conv22 = Conv2D(64,(3,3),activation='relu',padding='same',dilation_rate=(2,2),kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv21)\n",
    "    conv22 = Dropout(0.5)(conv22)\n",
    "    conv23 = Conv2D(64,(3,3),activation='relu',padding='same',dilation_rate=(3,3),kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv22)\n",
    "    conv24 = Conv2D(64,(3,3),activation='relu',padding='same',dilation_rate=(4,4),kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv23)\n",
    "    concat3 = concatenate([conv21,conv22,conv23,conv24],axis=1 )\n",
    "    drop3 = Dropout(0.5)(concat3)\n",
    "    conv31 = Conv2D(64,(1,1),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(drop3)\n",
    "    conv32 = Conv2D(64,(1,1),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv31)\n",
    "    conv32 = Dropout(0.5)(conv32)\n",
    "    conv33 = Conv2D(64,(1,1),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv32)\n",
    "    conv34 = Conv2D(64,(1,1),activation='relu',dilation_rate=(4,4),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv33)\n",
    "    concat4 = concatenate([conv31,conv32,conv33,conv34],axis=1 )\n",
    "    drop4 = Dropout(0.5)(concat4)\n",
    "    conv41 = Conv2D(64,(3,3),activation='relu',dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(drop4)\n",
    "    conv42 = Conv2D(64,(3,3),activation='relu',dilation_rate=(2,2),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv41)\n",
    "    conv42 = Dropout(0.5)(conv42)\n",
    "    conv43 = Conv2D(64,(3,3),activation='relu',dilation_rate=(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv42)\n",
    "    conv44 = Conv2D(64,(3,3),activation='relu',dilation_rate=(4,4),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-5))(conv43)\n",
    "    concat5 = concatenate([conv44,conv34,conv24,conv14,conv4],axis=1 )\n",
    "    drop5 = Dropout(0.5)(concat5)\n",
    "    final1 = Conv2D(128,(3,3),dilation_rate=(3,3),activation='relu',padding='same',kernel_initializer='glorot_uniform',kernel_regularizer=l2(1e-5))(drop5)\n",
    "    final1 = Conv2D(128,(1,1),dilation_rate=(1,1),activation='relu',padding='same',kernel_initializer='glorot_uniform',kernel_regularizer=l2(1e-5))(final1)\n",
    "    final1 = Dropout(0.5)(final1)\n",
    "    finallast = Conv2D(1,(1,1),dilation_rate=(1,1),activation='sigmoid',padding='same',kernel_initializer='glorot_uniform',kernel_regularizer=l2(1e-5))(final1)\n",
    "    model = Model(inputs=[inputs],outputs=[finallast])\n",
    "    return model\n",
    "def encoder_decoder(input_shape):\n",
    "    return Sequential([\n",
    "    \n",
    "        Conv2D(32, (3, 3),dilation_rate=(3,3), activation='relu', padding='same',input_shape=input_shape),\n",
    "        \n",
    "        MaxPooling2D((2,2), strides=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(64, (3, 3),dilation_rate=(2,2), activation='relu' ,padding='same',kernel_initializer='he_normal'),\n",
    "      \n",
    "        MaxPooling2D((2,2), strides=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(128, (3, 3),dilation_rate=(1,1), activation='relu',padding='same',kernel_initializer='he_normal'),\n",
    "        MaxPooling2D((2,2), strides=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(256, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'),\n",
    "        MaxPooling2D((2,2), strides=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same',kernel_initializer='he_normal'),\n",
    "      \n",
    "        UpSampling2D(size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(256, (3, 3),dilation_rate=(1,1), activation='relu', padding='same',kernel_initializer='he_normal'),\n",
    "      \n",
    "        UpSampling2D(size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(128, (3, 3),dilation_rate=(2,2),activation='relu', padding='same',kernel_initializer='he_normal'),\n",
    "       \n",
    "        UpSampling2D(size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(64, (3, 3),dilation_rate=(3,3), activation='relu',padding='same',kernel_initializer='he_normal'),\n",
    "        UpSampling2D(size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(32, (3, 3),dilation_rate=(3,3), activation='relu',padding='same',kernel_initializer='he_normal'),\n",
    "        Conv2D(1, (1, 1), activation='sigmoid')\n",
    "    ])\n",
    "inputs = Input((3,256,256))\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(1,1),kernel_size=(7,7),padding='same',kernel_regularizer=l2(1e-5))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x1 = Conv2D(filters=32,activation='relu',dilation_rate=(2,2),kernel_size=(5,5),padding='same',kernel_regularizer=l2(1e-5))(x)\n",
    "x1 = BatchNormalization()(x1)\n",
    "#x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(3,3),kernel_size=(3,3),padding='same',kernel_regularizer=l2(1e-5))(x1)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',kernel_initializer='he_normal')(x)\n",
    "#concat = concatenate([x1,x2,x3,x4],axis=1 )\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Conv2D(filters=256,activation='relu',kernel_size=(3,3),dilation_rate=(3,3),padding='same',kernel_regularizer=l2(1e-5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(filters=1,activation='sigmoid',kernel_size=(1,1),dilation_rate=(1,1),padding='same',kernel_regularizer=l2(1e-5))(x)\n",
    "modelDilated = Model(inputs=inputs,outputs=x)\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((3,256, 256))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2,2))(conv1)\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2,2))(conv2)\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPool2D(pool_size=(2,2))(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPool2D(pool_size=(2,2))(conv4)\n",
    "    pool4 = BatchNormalization()(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',activation='relu',kernel_regularizer=l2(1e-6))(conv5), conv4], axis=1 )\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',activation='relu',kernel_regularizer=l2(1e-6))(conv6), conv3], axis=1 )\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',activation='relu',kernel_regularizer=l2(1e-6))(conv7), conv2], axis=1 )\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(1e-6), kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',activation='relu',kernel_regularizer=l2(1e-6))(conv8), conv1], axis=1 )\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal',kernel_regularizer=l2(1e-6))(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Dropout(0.5)(conv9)\n",
    "    \n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal',kernel_regularizer=l2(1e-6))(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid',kernel_regularizer=l2(1e-6))(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5,decay=5e-6), loss=bce_dice, metrics=[dice_coef])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelDilated = dilatedKernels(input_shape=(3,256,256))\n",
    "print(modelDilated.summary())\n",
    "#history = model.fit(train,labels,batch_size=1,epochs=100,shuffle=True,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fcl_loss = focal_loss()\n",
    "modelDilated.compile(optimizer=Adam(lr=1e-5),loss=bce_dice,metrics=[jacard_coef, dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = encoder_decoder(input_shape=(1024,1024,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model1.compile(optimizer=Adam(lr=1e-3,decay=5e-4), loss=bce_dice, metrics=[dice_coef,jacard_coef])\n",
    "checkpoint = ModelCheckpoint(filepath='/home/ubuntu/DeepMobile/models/densenet/LargeDilatedKernels-scratch.h5',mode='max',\n",
    "                             monitor='val_dice_coef',verbose=1,save_best_only=True)\n",
    "#modelDilated.load_weights('/home/ubuntu/DeepMobile/models/unet/unetNoMaxPool3.h5')\n",
    "# we create two instances with the same arguments-\n",
    "\n",
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(rotation_range=90.,horizontal_flip=True,vertical_flip=True,\n",
    "                     zoom_range=0.2,fill_mode='mirror')\n",
    "image_datagen = ImageDataGenerator(rescale=1/255.,**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(rescale=1/255.,**data_gen_args)\n",
    "mask_datagen1 = ImageDataGenerator(rescale=1/255.,**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 30\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    '/home/ubuntu/DeepMobile/data/scratches/train/',target_size=(256, 256),\n",
    "    class_mode=None, batch_size=1,color_mode='rgb',\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    '/home/ubuntu/DeepMobile/data/scratches/label/',\n",
    "    class_mode=None,batch_size=1,target_size=(256, 256),color_mode='grayscale',\n",
    "    seed=seed)\n",
    "image_generator1 = image_datagen.flow_from_directory(\n",
    "    '/home/ubuntu/DeepMobile/data/scratches/test_Data/train/',target_size=(256, 256),\n",
    "    class_mode=None, batch_size=1,color_mode='rgb',\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator1 = mask_datagen.flow_from_directory(\n",
    "    '/home/ubuntu/DeepMobile/data/scratches/test_Data/labels/',\n",
    "    class_mode=None,batch_size=1,target_size=(256, 256),color_mode='grayscale',\n",
    "    seed=seed )\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "valid_generator = zip(image_generator1, mask_generator1)\n",
    "modelDilated.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=10000,validation_data=valid_generator,validation_steps=100,\n",
    "    epochs=100,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(height_shift_range=0.3,width_shift_range=0.3,fill_mode='mirror',horizontal_flip=True,vertical_flip=True,\n",
    "                     rotation_range=90.,\n",
    "                     )\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(trainNew, augment=True, seed=seed)\n",
    "\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_datagen.flow(x=trainNew[:200],batch_size=1,seed=1), mask_datagen.flow(x=labels[:200],batch_size=1,seed=1))\n",
    "valid_generator = zip(image_datagen.flow(x=trainNew[200:],batch_size=1,seed=1), mask_datagen.flow(x=labels[200:],batch_size=1,seed=1))\n",
    "\n",
    "model.fit_generator(callbacks=[checkpoint],validation_data=valid_generator,validation_steps=50,\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io as skio\n",
    "import matplotlib.pyplot as io\n",
    "from glob import glob\n",
    "import cv2\n",
    "testPath = glob('/home/ubuntu/DeepMobile/data/scratches/blacknwhite/2/353513070724013_back.png')\n",
    "testPath.sort()\n",
    "h=256\n",
    "w=256\n",
    "no = 182\n",
    "'''def FillImg(binImg):\n",
    "    _, contours, hieqrarchy = cv2.findContours(np.uint8(binImg), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    newBinImg = np.zeros((binImg.shape[0],binImg.shape[1]),np.uint8())\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    if(len(areas)>0):\n",
    "        max_index = np.argmax(areas)\n",
    "        cnt = contours[max_index]\n",
    "        cv2.drawContours(np.uint8(newBinImg), [cnt], 0, 255, -1)\n",
    "        \n",
    "    return newBinImg\n",
    "'''\n",
    "for i in range(len(testPath)):\n",
    "    #tokens = testPath[i].split('/)\n",
    "    #name = tokens[6].split('.')[0]\n",
    "    img =cv2.imread(testPath[i],3)\n",
    "\n",
    "    shape = img.shape\n",
    "    img = np.asarray(img).astype('uint8')\n",
    "   \n",
    "    \n",
    "    print(img.shape)\n",
    "    #img = cv2.resize(img,dsize=(w,h),interpolation=cv2.INTER_AREA)\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    #print(img.shape)\n",
    "    #label = cv.resize(label,dsize=(324,256))\n",
    "\n",
    "    #label = label.astype('uint8')\n",
    "    #img = img.reshape(1,h,w,3)\n",
    "\n",
    "    #print(img.shape)\n",
    "    #imgss = img\n",
    "    \n",
    "    img = img/255.\n",
    "    patches = prediction_patches(pad_input(img,patch_size=[h,w]),patch_size=[h,w])\n",
    "    patches = np.asarray(patches)\n",
    "    #label = label.reshape(512,648,1)\n",
    "    print(patches.shape)\n",
    "    patches = patches.transpose([0,3,1,2])\n",
    "    \n",
    "    skio.imshow(img)\n",
    "    skio.show()\n",
    "    #img = (img-np.mean(img))/np.std(img)\n",
    "    padded_input = pad_input(img)\n",
    "    shape = padded_input.shape\n",
    "    print(patches.shape)\n",
    "    predicted_patches = modelDilated.predict(patches,batch_size=1,verbose=1)\n",
    "    predicted_patches = predicted_patches.transpose([0,2,3,1])\n",
    "    predicted = reconstruct_patches(img_shape=shape,patches=predicted_patches)\n",
    "\n",
    "    print(np.max(predicted),np.min(predicted))\n",
    "    print(predicted.shape)\n",
    "    io.imshow(predicted)\n",
    "    io.show()\n",
    "    thresh = np.argwhere(predicted>0.2)\n",
    "    imgs = np.zeros(shape).astype('uint8')\n",
    "    print(thresh.shape)\n",
    "    for i in range(thresh.shape[0]):\n",
    "        imgs[thresh[i][0],thresh[i][1],0]=255\n",
    "    \n",
    "    skio.imshow(imgs[:,:,0])\n",
    "    skio.show()\n",
    "    '''io.imsave('/home/ubuntu/DeepMobile/data/output_scratches/original/dilated__{}.png'.format(int(no)),img)\n",
    "    io.imsave('/home/ubuntu/DeepMobile/data/output_scratches/predicted/dilated__{}.png'.format(int(no)),imgs[:,:,0])\n",
    "    no+=1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = img/255.\n",
    "img = (img- np.mean(img))/ np.std(img)\n",
    "img = img.reshape(1,320,480,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(img)\n",
    "print out.shape\n",
    "out = out.transpose([0,3,1,2])\n",
    "io.imshow(out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io as skio\n",
    "import matplotlib.pyplot as io\n",
    "from glob import glob\n",
    "testPath = glob('/home/ubuntu/De')\n",
    "for i in xrange(len(testPath)):\n",
    "    tokens = testPath[i].split('/')\n",
    "    name = tokens[6].split('.')[0]\n",
    "    img = skio.imread(testPath[i])\n",
    "    io.imshow(img)\n",
    "    io.show()\n",
    "    img  = img/255.\n",
    "    img = (img-np.mean(img))/np.std(img)\n",
    "    if img.shape==(320,480,3):\n",
    "        print 'yes'\n",
    "    else:\n",
    "        img = img.transpose([1,0,2])\n",
    "    img = img.reshape(1,320,480,3)\n",
    "    x = np.random.normal(loc=0.0, scale=1.0, size=(256,256,3))\n",
    "    predicted = model.predict(img)\n",
    "    predicted = predicted.transpose([0,3,1,2])\n",
    "    io.imshow(predicted[0][0])\n",
    "    io.show()\n",
    "    thresh = np.argwhere(predicted>0.000001)\n",
    "    for i in xrange(thresh.shape[0]):\n",
    "        predicted[thresh[i][0],thresh[i][1],thresh[i][2],thresh[i][3]]=255\n",
    "    \n",
    "    io.imshow(predicted[0][0])\n",
    "    io.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(4,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiramisu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('/home/ubuntu/DeepMobile/models/unet/unetNoMaxPool2.h5')\n",
    "modelDilated.save_weights('/home/ubuntu/DeepMobile/models/unet/unetNoMaxPool3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    \n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "    #img = np.asarray(img).astype('float32')\n",
    "    img = cv2.resize(frame,dsize=(1024,1024),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    #label = cv.resize(label,dsize=(324,256))\n",
    "\n",
    "    #label = label.astype('uint8')\n",
    "    img = img.reshape(1,1024,1024,3)\n",
    "    imgss = img\n",
    "    img = img/255.\n",
    "    #label = label.reshape(512,648,1)\n",
    "\n",
    "    \n",
    "    #img = (img-np.mean(img))/np.std(img)\n",
    "    predicted = model.predict(img)\n",
    " \n",
    "    \n",
    "    thresh = np.argwhere(predicted[:,:,:,0]>0.9)\n",
    "    imgs = np.zeros((1024,1024,3)).astype('uint8')\n",
    "   \n",
    "    for i in range(thresh.shape[0]):\n",
    "        \n",
    "        imgs[thresh[i][1],thresh[i][2],0]=imgss[0,thresh[i][1],thresh[i][2],0]\n",
    "        imgs[thresh[i][1],thresh[i][2],1]=imgss[0,thresh[i][1],thresh[i][2],1]\n",
    "        imgs[thresh[i][1],thresh[i][2],2]=imgss[0,thresh[i][1],thresh[i][2],2]\n",
    "    cv2.imshow(\"preview\", imgs)\n",
    "\n",
    "cv2.destroyWindow(\"preview\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/ubuntu/DeepMobile/models/myown/unetOverfit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(loc=0.0, scale=1.0, size=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = io.imread('/home/ubuntu/DeepMobile/data/scratches/label/label/1000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
